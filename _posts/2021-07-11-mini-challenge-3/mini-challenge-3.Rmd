---
title: "Mini-challenge 3"
description: |
  A short description of the post.
author:
  - name: Qian Ziwei
    url: https://example.com/norajones
date: 07-11-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.retina = 3,
                      echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

# 1. Overview

---

### 1.1 Background

In the country island of Kronos, the increasing noxious effects on health and farming have been related to the uncontrolled activity of GAStech, a natural gas operator, supported by corrupt government officials. On January 20th, 2014, a corporate meeting is held to celebrate the new-found fortune because of the initial public offering of the company. However, a series of rare events occur that lead to the disappearance of several employees. The Protectors of Kronos (POK), a social movement organization that has been fighting against water contamination and government corruption, is suspected in the disappearance.

As analysts, we were assigned with several tasks in order to identify risks and how they could have been mitigated more effectively.

### 1.2 Literature review


### 1.3 Objective

Using data and visual analytics to evaluate the changing levels of risk to the public and recommend actions for first responder:

* Distinguish meaningful event reports from typical chatter from junk or spam.

* Evaluate the level of the risk to the public evolves over the course of the evening. Consider the potential consequences of the situation and the number of people who could be affected.
Determine the appropriate location for first responders.

* The differences between dealing with this challenge in 2014 and dealing with it now.

### 1.4 Question 1

### 1.5 Question 2

### 1.6 Question 3

### 1.7 Question 4


---

# 2. Building the visualization

---

### 2.1 Setting up the environment/packages

First, we run this fist line of code to clear the environment and remove existing R objects(if any).

```{r}
rm(list = ls())
```

This code chunk checks if required packages are installed. If they are not installed, the next line of code will install them. The following line is then use to import the library into the current working environment.

```{r}
packages = c('readr','tidytext','data.table','lubridate','ggplot2',
             'caret','dplyr','tidyr','scales','quanteda','textdata',
             'stringr','stringi','reshape2','RColorBrewer','wordcloud',
             'forcats','igraph','ggraph','widyr','clock','knitr','tidyverse',
             'DT','hms','ggiraph','topicmodels','raster','sf','maptools',
             'rgdal','ggmap','sp','tmap','tmaptools','devtools','patchwork')
for(p in packages){
  if(!require(p,character.only = TRUE)){
    install.packages(p)
  }
  library(p,character.only = TRUE)
}
```

### 2.2 Importing data and changing data type

First, use <font color = blue>*read_csv()* </font> to import the csv file. 

```{r}
read1 <- read_csv("F:/visual/assignment and project/MC3/MC3/csv-1700-1830.csv",
                  col_types = list(col_character(),col_character(),col_character(),
                                   col_character(),col_double(),col_double(),
                                   col_character()))
read2 <- read_csv("F:/visual/assignment and project/MC3/MC3/csv-1831-2000.csv",
                  col_types = list(col_character(),col_character(),col_character(),
                                   col_character(),col_double(),col_double(),
                                   col_character()))
read3 <- read_csv("F:/visual/assignment and project/MC3/MC3/csv-2001-2131.csv",
                  col_types = list(col_character(),col_character(),col_character(),
                                   col_character(),col_double(),col_double(),
                                   col_character()))
```
Using function <font color = blue>*rbind()* </font> combine these three csv files with the same format.

```{r}
df <- rbind.data.frame(read1,read2,read3)
glimpse(df)
DT::datatable(df,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px',targets = c(4))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf'))) 
```

From the above table the <font color = red>*date(yyyyMMddHHmmss)*</font> is not in time format, so converting to date-time field. Because in the mini-challenge 3, all activities occur on the same day.Extract time(hms) data without date and transform.

```{r}
df$`date(yyyyMMddHHmmss)` <- date_time_parse(df$`date(yyyyMMddHHmmss)`,
                                 zone = "",
                                 format = "%Y%m%d %H%M%S")
df$time <- as_hms(ymd_hms((df$`date(yyyyMMddHHmmss)`)))
glimpse(df)
DT::datatable(df,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px',targets = c(4))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

### 2.3 Question 1

#### 2.3.1 Data processing
In question 1, extract the required data from the <font color = red>*df*</font> to make a new data frame. After reading all the data carefully, the terminology of <font color = red>*mbdata*</font> and <font color = red>*ccdata*</font> is very different, so separate the two files. Since ccdata is a police or fire department record, this dataset is labeled as a meaningful dataset.

```{r}
df1 <- subset(df, select = c("type","author","message"))
df_m <- subset(df1, type == "mbdata")
df_cc <- subset(df1,type == "ccdata")
df_cc$condition <- "meaningful"
DT::datatable(df_cc,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px',targets = c(3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

##### 2.3.1.1 Junk message

<font color = red>*JUNk definition*</font>: After reading all the data carefully, I have selected the following types of data.

* Authors like "KronosQuoth" will post content related to the three types of activities(rally, fire to collapsed, accident to gunshot) in this challenge, but cannot or rarely provide important information such as location. The content is mostly emotional and cathartic.

* Content that includes the term "#Grammar" is mostly unrelated to important events in mini-challenge 3.

* Content containing "RT" is a forwarding of other people's messages, providing the same information repeatedly. And, the number of "RT" message is very large.

```{r}
junk <- df_m %>%
  filter(str_detect(author,"KronosQuoth|Clevvah4Eva|choconibbs|trollingsnark|
                    blueSunshine|whiteprotein|FriendsOfKronos|junkman377|
                    junkman995|redisrad|roger_roger|cheapgoods998|rockinHW|
                    panopticon|dels4realz|eazymoney|cleaningFish")|
           str_detect(message,"#Grammar|RT"))
```


##### 2.3.1.2 Meaningful message

<font color = red>*Meaningful definition*</font>: After reading all the data carefully, I have selected the following types of data.

* Information released by authors who are more official or authoritative. Author like "POK","AbilaPoliceDepartment".

* Information released by authors are witnesses to events and publishes information that provides important information. Authors like "magaMan","Sara_Nespola".

* Content that includes terms like "fire","rally" is mostly related to the important events in mini-challenge 3.

```{r}
meaningful <- df_m %>%
  filter(str_detect(author,"POK|AbilaPost|CentralBulletin|ourcountryyourrights|
  MindOfKronos|Viktor-E|maha_Homeland,anaregents|wordWatcher|InternationalNews|
  HomelandIlluminations|NewsOnlineToday|AbilaPoliceDepartment|KronosStar|magaMan|
  Sara_Nespola|protoGuy|SiaradSea|AbilaFire|footfingers|truthforcadau|truccotrucco|
  dangermice|trapanitweets|sofitees|brewvebeenserved|hennyhenhendrix")|
           str_detect(message,"POK Rally|@POK|Abila City Park|POK rally|Sylvia Marek|
                      #POKrally|#POK|#POKRally|#porkrally|terrorists|#KronosStar|
                      #Ailbapost|#IntNews|@AlibaPost|#CentralBulletin|Marek|violence|
                      @ourcountryyourrights|#POKlove|Sylvia|Di Stefan|@MindOfKronos|
                      @Viktor-E|@InternationalNews|Lucio|Death|Audrey McConnel Newman|
                      @Officia1AbilaPost|#POKRallyinthepark|#POKpeace|#terror|cops|cop|
                      Jakab|@anaregents|@maha_homeland|Anarchist|#POKRallyinthepark|kidnapping|
                      crime|#terrorists|#APD|APD|Parla St|Egeou St|Alm St|Sanjorge|
                      crackdown|River Soldies|leaving|Human Trafficking rally|kidnap|
                      missing|#SavePeople|Joni Mitchell|Newman|murder|Elian|fire|
                      Achilleos|AFD|burn(delet writinLazy)|Fire Departmentsmoke|
                      bonfire, Dancing Dolphin apartment, @HomelandIlluminations|
                      fire trucks|#HELPME|ambulance|#dancingdolfinfire|occupants|
                      #DancingDolphinsFire|@dancingdolphin|#dancingdolphinfire|floor|
                      floors|fireman|firefighters|firefighter|PD|Paramedics|
                      smoke inhalation|injuries|scene|precaution fire officials|
                      evacuated|evacuate|evacuations|evacuation|evacuating|rescued|
                      out of control|AFD|under control|trapped|collapsed|blaze|
                      escalated|traffic|car hit|Souliou|black van|driver|bicyclist|
                      Schaber|#jerkdrivers|hit|injured|L829|run incident|hit and run|
                      bike|wheels|accident|biker|in pursuit|Henri|gelatogalore|
                      gelato|explosion??|gun|shots|gunshot|shot|Gunfire|gun fire|
                      shooting|shooter|chouting|killed|dead|gunman|hostages|
                      in danger|hurt|hostage|Ithakis and Alexandrias|kill|SWAT|
                      swat|standoff|negotiating|negotiator|negoitations|Carly|
                      yelling|screaming|chasing|dude|stand-off|standoff|stand off|
                      ends|caught|over|end|ended|rescued"))
```

##### 2.3.1.3 Meaningless message

<font color = red>*Meaningless definition*</font>: After reading all the data carefully, I have selected the following types of data.

* Content that includes terms like "fire","rally" which is related to the events but is used to express emotions and can not provide important information.

* Content that is unrelated to the events, but has their own objectives like sharing the information of shops.

This group is obtained by subtracting other groups from the <font color = red>*df_m*</font> through <font color = blue>*anti_join()*</font> function.

```{r}
meaningful <- dplyr::anti_join(meaningful,junk,by = c("type", "author", "message"))

combinedata <- rbind.data.frame(meaningful, junk)

meaningless <- dplyr::anti_join(df_m,combinedata,by = c("type", "author", "message"))
```

##### 2.3.1.4 Combining meaningful,meaninfless and junk message

Combine meaningful,meaningless and junk data and add a new label column.

```{r}
junk$condition <- "junk"
meaningful$condition <- "meaningful"
meaningless$condition <- "meaningless"

finalq1 <- rbind.data.frame(meaningful,junk, meaningless)
DT::datatable(finalq1,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px', targets = c(3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

##### 2.3.1.5 Cleaning the dataset before token

Use <font color = blue>*stringr package*</font> to remove punctuation, @, #, < and Chinese characters from messages. The messages in <font color = red>*ccdata*</font> are very clean and do not require special handling.

```{r}
finalq1$message <- str_replace_all(finalq1$message,'[[:punct:]]+', "")

finalq1$message <- str_replace_all(finalq1$message,fixed("@"),"")

finalq1$message <- str_replace_all(finalq1$message,fixed("#"),"")

finalq1$message <- str_replace_all(finalq1$message,fixed("<"),"")

finalq1$message <- str_replace_all(finalq1$message,"[\u4e00-\u9fa5]+", "")
```

The messages in the table below is clean.

```{r}
DT::datatable(finalq1,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px', targets = c(3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```


##### 2.3.1.6 Token the data and custom stop-words.

Exclude stop words from the text and use <font color = blue>*tibble()*</font> to custom stop words selected according to the content of the text.

```{r}
tidy_m <- finalq1 %>%
  unnest_tokens(word, message) %>%
  count(condition,word,sort = TRUE)


data(stop_words)
tidy_m <- tidy_m %>%
  anti_join(stop_words)

my_stopwords <- tibble(word = c("zawahiri","yikes","yehu","yeah",
                                "yay","ya","xx3942","wuz","wow",
                                "dr"))
tidy_m <- tidy_m %>%
  anti_join(my_stopwords)

tidy_cc <- df_cc %>%
  unnest_tokens(word,message) %>%
  count(word, sort = TRUE)

DT::datatable(tidy_m,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '60px', targets = c(0:3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))

DT::datatable(tidy_cc,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '60px', targets = c(0:2))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

#### 2.3.2 Simple EDA

The graph below is the word number distribution of junk,meaningful and meaningless group. The junk message has high repetition rate of words.

```{r}
ggplot(tidy_m,aes(n,fill = condition))+
  geom_histogram(show.legend = FALSE)+
  scale_fill_brewer(palette = "Pastel1")+
  xlim(0,100)+
  facet_wrap(~condition, ncol = 2,scales = "free_y")
```

The graph below is the top 15 word(n) of junk,meaningful and meaningless group.

* Junk group

    * Most of them are words related to POK Rally, used to vent feelings or words related to success. There are also statements against the government and police. Words like "success","life".
    
    * There are also obvious spam features such as rt and grammar. These message number is very large and do not provide useful information.
    
* Meaningful group 

    * Words can provide information about the important people of the events. Words like "viktore".

    * Words can provide information on the important processes of the events. Words like "standoff".
    
    * Words can provide information on the important locations of the events. words like "dolphin","dancing".
    
* Meaningless group  
 
    * Content sent by individuals for certain purposes.
    
    * Content sent by businesses to promote their company or products. Word like "credit" is issued to promote a credit card.
    
```{r}
tidy_m %>%
  group_by(condition) %>%
  slice_max(n, n= 15) %>%
  ungroup() %>%
  mutate(word = reorder_within(word,n,condition)) %>%
  ggplot(aes(x = n,
             y= word,
             fill =condition))+
  geom_col(show.legend = FALSE)+
  scale_fill_brewer(palette = "Pastel1")+
  scale_y_reordered()+
  facet_wrap(~ condition, ncol = 2,scales = "free")+
  ggtitle("mbdata") +
  theme(plot.title = element_text(size=10,
                                  hjust = 0.4))+
  labs(y = NULL)
```

The graph of <font color = red>*ccdata*</font> shows that the events like "fire","traffic". Word like "vehicle" is issued to the event--"From hit-and-run accident to shooting and standoff".

```{r}
tidy_cc %>%
  slice_max(n,n = 15) %>%
  ggplot(aes(x = n,
             y= reorder(word,n)))+
  geom_col(show.legend = FALSE, fill = "darkgoldenrod1")+
  ggtitle("ccdata_meaningful") +
  theme(plot.title = element_text(size=10,
                                  hjust = 0.45))+
  labs(y = NULL)
```


#### 2.3.3 Visualization the ccdata and mbdata

##### 2.3.3.1 Wordcloud

The conclusion is similar to Simple EDA. 

```{r}
wordcloud_m <- tidy_m

wordcloud_m <- finalq1 %>%
  filter(condition == "meaningful") %>%
  unnest_tokens(word, message)%>%
  anti_join(stop_words) %>%
  anti_join(my_stopwords) %>%
  count(word,sort = TRUE)%>%
  with(wordcloud(word,n,max.words = 100))

wordcloud_m <- finalq1 %>%
  filter(condition == "meaningless") %>%
  unnest_tokens(word, message)%>%
  anti_join(stop_words) %>%
  anti_join(my_stopwords) %>%
  count(word,sort = TRUE)%>%
  with(wordcloud(word,n,max.words = 100))

wordcloud_m <- finalq1 %>%
  filter(condition == "junk") %>%
  unnest_tokens(word, message)%>%
  count(word,sort = TRUE)%>%
  anti_join(stop_words) %>%
  anti_join(my_stopwords) %>%
  with(wordcloud(word,n,max.words = 100))

tidy_cc %>%
  with(wordcloud(word,n,max.words = 100))
```

##### 2.3.3.2 tf-idf visualization

Use the <font color = blue>*bind_tf_idf()*</font> to find the important words for the different categories.

* Junk: The graph shows that for junk message, retweets(like "rt"), social media accounts(like "kronosstar") and emotive(like "success") words are important component.

* Meaningful: The graph shows that for meaningful message, government departments(like "apd","afd") or emergency services, important people at events(like "sylvia") are important component.

* Meaningless: The graoh shows that for meaningless message, company event slogans(like "nobanks") are important component.

```{r}
m_tf_idf <- tidy_m %>%
  bind_tf_idf(word,condition,n)

m_tf_idf %>%
  arrange(desc(tf_idf))

m_tf_idf %>%
  group_by(condition) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>%
  mutate(word = reorder_within(word,tf_idf,condition)) %>%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = condition))+
  scale_fill_brewer(palette = "Pastel1")+
  scale_y_reordered()+
  geom_col(show.legend = FALSE)+
  facet_wrap(~condition,ncol = 2,scales = "free")+
  ggtitle("mbdata") +
  theme(plot.title = element_text(size=10,
                                  hjust = 0.4))+
  labs(y = NULL)
```

##### 2.3.3.3 Bigrams visualization

Use the <font color = blue>*bigram*</font> to find the important phrases for the different categories.

Actually,there is no big difference for these three categories. But meaningful messages contain more specific time and place phrases.

```{r}
meaningful_bigrams <- meaningful %>%
  unnest_tokens(bigram,message,token = "ngrams", n = 2)
meaningful_bigrams %>%
  count(bigram, sort = TRUE)
meaningful_separated <- meaningful_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
meaningful_filtered <- meaningful_separated %>%
  filter(!word1 %in% my_stopwords) %>%
  filter(!word2 %in% my_stopwords)
meaningful_filtered <- meaningful_filtered %>%
    filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
meaningful_counts <- meaningful_filtered %>% 
  count(word1, word2, sort = TRUE)
meaningful_graph <- meaningful_counts %>%
  filter(n > 4) %>%
  graph_from_data_frame()

set.seed(2020)
a <- grid::arrow(type = "closed",length = unit(.15,"inches"))

ggraph(meaningful_graph,layout = "fr")+
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

junk_bigrams <- junk %>%
  unnest_tokens(bigram,message,token = "ngrams", n = 2)
junk_bigrams %>%
  count(bigram, sort = TRUE)
junk_separated <- junk_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
junk_filtered <- junk_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
junk_counts <- junk_filtered %>% 
  count(word1, word2, sort = TRUE)
junk_graph <- junk_counts %>%
  filter(n > 50) %>%
  graph_from_data_frame()
set.seed(2020)
a <- grid::arrow(type = "closed",length = unit(.15,"inches"))

ggraph(meaningful_graph,layout = "fr")+
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

meaningless_bigrams <- meaningless %>%
  unnest_tokens(bigram,message,token = "ngrams", n = 2)
meaningless_bigrams %>%
  count(bigram, sort = TRUE)
meaningless_separated <- meaningless_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
meaningless_filtered <- meaningless_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
meaningless_counts <- meaningless_filtered %>% 
  count(word1, word2, sort = TRUE)
meaningless_graph <- meaningless_counts %>%
  filter(n > 4) %>%
  graph_from_data_frame()
set.seed(2020)
a <- grid::arrow(type = "closed",length = unit(.15,"inches"))

ggraph(meaningful_graph,layout = "fr")+
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```

#### 2.3.4 Question 1 conclusion

We can distinguish the differences according to the characteristics of the words used in each category.

* Junk: The characteristics of the words in junk category: 

    * Most of them are words related to POK Rally, used to vent feelings or words related to success. There are also statements against the government and police. Words like “success”,“life”.

    * There are also obvious spam features such as rt and grammar. These message number is very large and do not provide useful information.
    
    * There are many social media accounts(like “kronosstar”).
    
* Meaningful: The characteristics of the words in meaningful category: 

    * Words can provide information about the important people of the events. Words like “viktore”.

    * Words can provide information on the important processes of the events and important government or emergency services. Words like “standoff”,"afd" and "apd".

    * Words can provide information on the important locations of the events. words like “dolphin”,“dancing”.
    
* Meaningless: The characteristics of the words in meaningless category:

    * Content sent by individuals for certain purposes.

    * Content sent by businesses to promote their company or products. Word like “credit” is issued to promote a credit card.

### 2. 4 Question 2  

#### 2.4.1 Data preparation

##### 2.4.1.1 Getting a whole meaningful data

Repeating the process above and get a whole meaningful dataset.

```{r}
q2_m <- subset(df, type == "mbdata")
q2_cc <- subset(df,type == "ccdata")
q2_junk <- q2_m %>%
    filter(str_detect(author,"KronosQuoth|Clevvah4Eva|choconibbs|trollingsnark|
                    blueSunshine|whiteprotein|FriendsOfKronos|junkman377|
                    junkman995|redisrad|roger_roger|cheapgoods998|rockinHW|
                    panopticon|dels4realz|eazymoney|cleaningFish")|
           str_detect(message,"#Grammar|RT"))


q2_meaningful <- q2_m %>%
  filter(str_detect(author,"POK|AbilaPost|CentralBulletin|ourcountryyourrights|
  MindOfKronos|Viktor-E|maha_Homeland,anaregents|wordWatcher|InternationalNews|
  HomelandIlluminations|NewsOnlineToday|AbilaPoliceDepartment|KronosStar|magaMan|
  Sara_Nespola|protoGuy|SiaradSea|AbilaFire|footfingers|truthforcadau|truccotrucco|
  dangermice|trapanitweets|sofitees|brewvebeenserved|hennyhenhendrix")|
           str_detect(message,"POK Rally|@POK|Abila City Park|POK rally|Sylvia Marek|
                      #POKrally|#POK|#POKRally|#porkrally|terrorists|#KronosStar|
                      #Ailbapost|#IntNews|@AlibaPost|#CentralBulletin|Marek|violence|
                      @ourcountryyourrights|#POKlove|Sylvia|Di Stefan|@MindOfKronos|
                      @Viktor-E|@InternationalNews|Lucio|Death|Audrey McConnel Newman|
                      @Officia1AbilaPost|#POKRallyinthepark|#POKpeace|#terror|cops|cop|
                      Jakab|@anaregents|@maha_homeland|Anarchist|#POKRallyinthepark|kidnapping|
                      crime|#terrorists|#APD|APD|Parla St|Egeou St|Alm St|Sanjorge|
                      crackdown|River Soldies|leaving|Human Trafficking rally|kidnap|
                      missing|#SavePeople|Joni Mitchell|Newman|murder|Elian|fire|
                      Achilleos|AFD|burn(delet writinLazy)|Fire Departmentsmoke|
                      bonfire, Dancing Dolphin apartment, @HomelandIlluminations|
                      fire trucks|#HELPME|ambulance|#dancingdolfinfire|occupants|
                      #DancingDolphinsFire|@dancingdolphin|#dancingdolphinfire|floor|
                      floors|fireman|firefighters|firefighter|PD|Paramedics|
                      smoke inhalation|injuries|scene|precaution fire officials|
                      evacuated|evacuate|evacuations|evacuation|evacuating|rescued|
                      out of control|AFD|under control|trapped|collapsed|blaze|
                      escalated|traffic|car hit|Souliou|black van|driver|bicyclist|
                      Schaber|#jerkdrivers|hit|injured|L829|run incident|hit and run|
                      bike|wheels|accident|biker|in pursuit|Henri|gelatogalore|
                      gelato|explosion??|gun|shots|gunshot|shot|Gunfire|gun fire|
                      shooting|shooter|chouting|killed|dead|gunman|hostages|
                      in danger|hurt|hostage|Ithakis and Alexandrias|kill|SWAT|
                      swat|standoff|negotiating|negotiator|negoitations|Carly|
                      yelling|screaming|chasing|dude|stand-off|standoff|stand off|
                      ends|caught|over|end|ended|rescued"))


q2_meaningful <- dplyr::anti_join(q2_meaningful,q2_junk)
```

##### 2.4.1.2 Dividing three events and processing data separately

##### Try to do LDA on the meaningful dataset, but the results of LDA is not good. So change to use the key words to define each event.

```{r}
q2_lda <- subset(q2_meaningful,select = c("type","date(yyyyMMddHHmmss)","author",
                                 "message","latitude","longitude","time"))
q2_lda <- na.omit(q2_lda)

tidy_q2 <- q2_lda %>%
  unnest_tokens(word,message)

q2_wordcount <- tidy_q2 %>%
  anti_join(stop_words)

my_stopwords <- tibble(word = c("zawahiri","yikes","yehu","yeah",
                                "yay","ya","xx3942","wuz","wow",
                                "dr"))
q2_wordcount <- q2_wordcount %>%
  anti_join(my_stopwords) %>%
  count(author,word,sort = TRUE)
q2_wordcount

q2_dtm <- q2_wordcount %>%
  cast_dfm(author,word,n)

q2_author_lda <- LDA(q2_dtm,k = 3, control = list(seed = 1234))

q2_topics <- tidy(q2_author_lda,matrix = "beta")

q2_topics
q2_topics %>%
  group_by(topic) %>%
  top_n(10,beta) %>%
  ungroup() %>%
  mutate(term = reorder_within(term,beta,topic)) %>%
  ggplot(aes(beta,term,fill = topic))+
  scale_y_reordered()+
  geom_col(show.legend = FALSE)+
  facet_wrap(~topic,ncol = 2,scales = "free")+
  ggtitle("meaningful") +
  theme(plot.title = element_text(size=10,
                                  hjust = 0.4))+
  labs(y = NULL)

q2_author_lda2 <- LDA(q2_dtm,k = 4, control = list(seed = 1234))

q2_topics2 <- tidy(q2_author_lda2,matrix = "beta")

q2_topics2
q2_topics2 %>%
  group_by(topic) %>%
  top_n(10,beta) %>%
  ungroup() %>%
  mutate(term = reorder_within(term,beta,topic)) %>%
  ggplot(aes(beta,term,fill = topic))+
  scale_y_reordered()+
  geom_col(show.legend = FALSE)+
  facet_wrap(~topic,ncol = 2,scales = "free")+
  ggtitle("meaningful") +
  theme(plot.title = element_text(size=10,
                                  hjust = 0.4))+
  labs(y = NULL)

q2_author_lda3 <- LDA(q2_dtm,k = 5, control = list(seed = 1234))

q2_topics3 <- tidy(q2_author_lda3,matrix = "beta")

q2_topics3
q2_topics3 %>%
  group_by(topic) %>%
  top_n(5,beta) %>%
  ungroup() %>%
  mutate(term = reorder_within(term,beta,topic)) %>%
  ggplot(aes(beta,term,fill = topic))+
  scale_y_reordered()+
  geom_col(show.legend = FALSE)+
  facet_wrap(~topic,ncol = 2,scales = "free")+
  ggtitle("meaningful") +
  theme(plot.title = element_text(size=10,
                                  hjust = 0.4))+
  labs(y = NULL)
```

##### POK event

Using the important words of pok rally event to choose the pok rally relevant messages from the meaningful dataset. 

```{r}
q2_rally_m <- q2_meaningful %>%
  filter(str_detect(message,"pokrally|Abila City Park|Stand Up Speak Up|Sylvia Marek|Audrey McConnell Newman, Professor Lorenzo Di Stefano|Lucio Jakab|Viktor-E|Sylvia|Marek|Newman|Stefano|Di Stefano|Lucio|Jakab"))

q2_rally_cc <- q2_cc %>%
  filter(str_detect(message,"ABILA CITY PARK|CROWD"))

q2_rally <- rbind(q2_rally_m,q2_rally_cc)

DT::datatable(q2_rally,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px', targets = c(4))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

Clean the message content.

```{r}
q2_rally$message <- str_replace_all(q2_rally$message,'[[:punct:]]+', "")

q2_rally$message <- str_replace_all(q2_rally$message,fixed("@"),"")

q2_rally$message <- str_replace_all(q2_rally$message,fixed("#"),"")

q2_rally$message <- str_replace_all(q2_rally$message,fixed("<"),"")

q2_rally$message <- str_replace_all(q2_rally$message,"[\u4e00-\u9fa5]+", "")
```

Token the dataset.

```{r}
q2_rally_tidy <- q2_rally %>%
  unnest_tokens(word, message)

data(stop_words)
q2_rally_tidy <- q2_rally_tidy %>%
  anti_join(stop_words)

my_stopwords <- tibble(word = c("zawahiri","yikes","yehu","yeah",
                                "yay","ya","xx3942","wuz","wow",
                                "dr"))
q2_rally_tidy <- q2_rally_tidy %>%
  anti_join(my_stopwords)

DT::datatable(q2_rally_tidy,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '60px', targets = c(0:3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

##### Fire in Dancing Dolphin

Using the important words of "Fire in Dancing Dolphin" event to choose the fire relevant messages from the meaningful dataset. 

```{r}
q2_fire_m <- q2_meaningful %>%
  filter(str_detect(message,"fire|dolphin|dancing|building|apartment|Madeg|dispatch|afd|floor|floors|fireman|firefighters|firefighter|evacuate|evacuated|evacuating|evacuation|trapped|injuries|scene|trapped|collapsed|blaze|escalated"))

q2_fire_cc <- q2_cc %>%
  filter(str_detect(message,"Fire|Crime|scene"))

q2_fire <- rbind(q2_fire_m,q2_fire_cc)

DT::datatable(q2_fire,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px', targets = c(4))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

Clean the message content.

```{r}
q2_fire$message <- str_replace_all(q2_fire$message,'[[:punct:]]+', "")

q2_fire$message <- str_replace_all(q2_fire$message,fixed("@"),"")

q2_fire$message <- str_replace_all(q2_fire$message,fixed("#"),"")

q2_fire$message <- str_replace_all(q2_fire$message,fixed("<"),"")

q2_fire$message <- str_replace_all(q2_fire$message,"[\u4e00-\u9fa5]+", "")
```

Token the dataset.

```{r}
q2_fire_tidy <- q2_fire %>%
  unnest_tokens(word, message)

data(stop_words)
q2_fire_tidy <- q2_fire_tidy %>%
  anti_join(stop_words)

my_stopwords <- tibble(word = c("zawahiri","yikes","yehu","yeah",
                                "yay","ya","xx3942","wuz","wow",
                                "dr"))
q2_fire_tidy <- q2_fire_tidy %>%
  anti_join(my_stopwords)

DT::datatable(q2_fire_tidy,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '60px', targets = c(0:3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

##### From hit-and-run accident to shooting and standoff

Using the important words of "From hit-and-run accident to shooting and standoff" event to choose the fire relevant messages from the meaningful dataset. 

```{r}
q2_accident_m <- q2_meaningful %>%
  filter(str_detect(message,"shooting|stanoff|hostage|swat|negotiation|fight|arrest|hit|van| driver|bicyclist|accident|incident|bike|L829|pursuit|gun|shot|kill|dead|yelling|screaming|negotiatingnegotiator|caught|over|end|shoot|shot|chasing"))

q2_accident_cc <- q2_cc %>%
  filter(str_detect(message,"van|pursuit|accident|vandalism|swat"))

q2_accident <- rbind(q2_accident_m,q2_accident_cc)

DT::datatable(q2_accident,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '400px', targets = c(4))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

Clean the message content.

```{r}
q2_accident$message <- str_replace_all(q2_accident$message,'[[:punct:]]+', "")

q2_accident$message <- str_replace_all(q2_accident$message,fixed("@"),"")

q2_accident$message <- str_replace_all(q2_accident$message,fixed("#"),"")

q2_accident$message <- str_replace_all(q2_accident$message,fixed("<"),"")

q2_accident$message <- str_replace_all(q2_accident$message,"[\u4e00-\u9fa5]+", "")
```

Token the dataset.

```{r}
q2_accident_tidy <- q2_accident %>%
  unnest_tokens(word, message)

data(stop_words)
q2_accident_tidy <- q2_accident_tidy %>%
  anti_join(stop_words)

my_stopwords <- tibble(word = c("zawahiri","yikes","yehu","yeah",
                                "yay","ya","xx3942","wuz","wow",
                                "dr"))
q2_accident_tidy <- q2_accident_tidy %>%
  anti_join(my_stopwords)

DT::datatable(q2_accident_tidy,filter = 'top',
              extensions = 'Buttons',
              options = list(autoWidth = FALSE, columnDefs = list(list(width = '60px', targets = c(0:3))),
                             dom='Bfrtip',
                             buttons=c('copy', 'csv', 'excel', 'print', 'pdf')))
```

#### 2.4.2 Visualization different events

### Visualizaiton different events

From the processing of the data, it was found that there were three events in the mini-challenge 3.

* The POK rally event, which focuses on the start time of the rally, the time of the different speakers' speech and the end time.

* Fire in Dancing Dolphin, which focused on the start of the fire, rescue, evacuation and the final explosion.

* From hit-and-run accident to shooting and standoff, which focused on the traffic accident, the hostage situation, the confrontation with the police, the negotiations and the rescue of the hostages.

##### 2.4.2.1 POK event

POK rally was held on Abila City Park. About 2000 people gathered there and heavy police was disposed.

* These two graphs shows the beginning time of POK rally is 17:00 and ending time is 19:15.

```{r}
q2_rally_tidy%>%
  filter(str_detect(word,"rally")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#99CCFF")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y ="rally")
 
q2_rally_tidy%>%
  filter(str_detect(word,"pok")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#99CCFF")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y ="pok")
```

The most important one in the speech is the POK leader Sylvia Marek, who played a similar role to host. At the begining, POK leader Sylvia Marek opened with a speech and introduced the guests, Dr. Audrey McConnell Newman, Professor Lorenzo Di Stefano and Lucio Jakab. 
From the diagram, there are intermittent references to Sylvia Marek throughout the speech.

```{r}
q2_rally_tidy%>%
  filter(str_detect(word,"sylvia|marek")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#6699CC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y ="sylvia|marek")
```

The first speaker is Viktor-E who also provided the music of the event. His 

```{r}
q2_rally_tidy%>%
  filter(str_detect(word,"viktor")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#6699CC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y ="viktor")

q2_rally_tidy%>%
  filter(str_detect(word,"audrey|mcConnell|newman")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#6699CC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y ="audrey|mcConnell|newman")

q2_rally_tidy%>%
  filter(str_detect(word,"lucio|jakab")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#6699CC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y ="audrey|mcConnell|newman")

q2_rally_tidy%>%
  filter(str_detect(word,"lorenzo|di|stefano")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#6699CC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y ="lorenzo|di|stefano")

```

##### 2.4.2.2 Fire in Dancing Dolphin

```{r}
q2_fire_tidy%>%
  filter(str_detect(word,"fire|dolphin|dancing|building|apartment")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#FFCCCC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y = NULL)
 
q2_fire_tidy%>%
  filter(str_detect(word,"floor|floors|upper||resident|trapped")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#FFCCCC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y =NULL)

q2_fire_tidy%>%
  filter(str_detect(word,"afd|police|cop|cops|fireman|firefighter")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#FFCCCC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y =NULL)

q2_fire_tidy%>%
  filter(str_detect(word,"ambulance|injury|injuries|evacuated|evacuating|evacuation|evacuate")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#FF99CC")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y =NULL)

q2_fire_tidy%>%
  filter(str_detect(word,"control")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#CC6699")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y = "control")

q2_fire_tidy%>%
  filter(str_detect(word,"collapsed|blaze|escalated|explosion")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#993366")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y =NULL)
```

##### 2.4.2.3 From hit-and-run accident to shooting and standoff

```{r}
q2_accident_tidy%>%
  filter(str_detect(word,"hit|run|van|bicyclist|driver|incident|accident|bike|pursuit")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#99CC99")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y = NULL)
 
q2_accident_tidy%>%
  filter(str_detect(word,"gun|shoot|shot|histage")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#00CC66")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y =NULL)

q2_accident_tidy%>%
  filter(str_detect(word,"killed|dead")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#009900")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
    labs(y =NULL)

q2_accident_tidy%>%
  filter(str_detect(word,"standoff|negotiating|negotiate|negotiator|negotiation|yelling|screaming|chasing")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#006600")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y =NULL)

q2_accident_tidy%>%
  filter(str_detect(word,"end|over|ocaught|rescued")) %>%
  ggplot(aes(x = time)) +
  geom_histogram(fill = "#003300")+
  coord_cartesian(xlim = c(61200,77460))+
  theme(panel.grid=element_blank(),axis.text.x= element_text(angle=60, hjust= 1))+
  labs(y =NULL)
```

### 2.5 Question 3

#### 2.5.1 Data processing

```{r}
bgmap <- raster("F:/visual/assignment and project/MC3/MC3/Geospatial/MC2-tourist.tif")

bgmap
abila_st <- st_read(dsn = "F:/visual/assignment and project/MC3/MC3/Geospatial",
                    layer = "Abila")
abila <- read_sf("F:/visual/assignment and project/MC3/MC3/Geospatial/Abila.shp")

q3_gps <- subset(q2_meaningful,select = c("type","date(yyyyMMddHHmmss)","author",
                                 "message","latitude","longitude","time"))

gps_m <- na.omit(q3_gps)

p <- gps_m %>%
  count(longitude,latitude)
p$n <- as.numeric(p$n)

gps_sf <- st_as_sf(p,
                   coords = c("longitude","latitude"),
                   crs = 4326)
gps_point <- gps_sf %>%
  st_cast("MULTIPOINT")
```


```{r}
q3_rally_gps <- subset(q2_rally_m,select = c("type","date(yyyyMMddHHmmss)","author",
                                 "message","latitude","longitude","time"))
gps_rally_m <- na.omit(q3_rally_gps)
gps_rally_sf <- st_as_sf(gps_rally_m,
                   coords = c("longitude","latitude"),
                   crs = 4326)

q3_rally_gps <- na.omit(q3_rally_gps)

rally_count <- q3_rally_gps %>%
  count(longitude,latitude)
rally_count$n <- as.numeric(rally_count$n)

gps_rally_sf <- st_as_sf(rally_count,
                   coords = c("longitude","latitude"),
                   crs = 4326)
gps_rally_point <- gps_rally_sf %>%
  st_cast("MULTIPOINT")
```

```{r}
q3_fire_gps <- subset(q2_fire_m,select = c("type","date(yyyyMMddHHmmss)","author",
                                 "message","latitude","longitude","time"))
gps_fire_m <- na.omit(q3_fire_gps)
gps_fire_sf <- st_as_sf(gps_fire_m,
                   coords = c("longitude","latitude"),
                   crs = 4326)

q3_fire_gps <- na.omit(q3_fire_gps)

fire_count <- q3_fire_gps %>%
  count(longitude,latitude)
fire_count$n <- as.numeric(fire_count$n)

gps_fire_sf <- st_as_sf(fire_count,
                   coords = c("longitude","latitude"),
                   crs = 4326)
gps_fire_point <- gps_fire_sf %>%
  st_cast("MULTIPOINT")

```

```{r}
q3_accident_gps <- subset(q2_accident_m,select = c("type","date(yyyyMMddHHmmss)","author",
                                 "message","latitude","longitude","time"))
gps_accident_m <- na.omit(q3_accident_gps)
gps_accident_sf <- st_as_sf(gps_accident_m,
                   coords = c("longitude","latitude"),
                   crs = 4326)

q3_accidnet_gps <- na.omit(q3_accident_gps)

accident_count <- q3_accident_gps %>%
  count(longitude,latitude)
accident_count$n <- as.numeric(accident_count$n)
accident_count <- na.omit(accident_count)

gps_accident_sf <- st_as_sf(accident_count,
                   coords = c("longitude","latitude"),
                   crs = 4326)
gps_accident_point <- gps_accident_sf %>%
  st_cast("MULTIPOINT")
```

```{r}
tmap_mode("view")
tm_shape(bgmap,point.per = "feature")+
  tm_rgb(r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_point,is.master = TRUE, point.per = 'feature')+
  tm_dots(size ="n")

tmap_mode("view")
tm_shape(bgmap)+
  tm_rgb(r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_rally_point) +
  tm_dots(size = "n")

tmap_mode("view")
tm_shape(bgmap)+
  tm_rgb(r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_fire_point) +
  tm_dots(size = "n")

tmap_mode("view")
tm_shape(bgmap)+
  tm_rgb(r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_accident_point) +
  tm_dots(size = "n")

```

